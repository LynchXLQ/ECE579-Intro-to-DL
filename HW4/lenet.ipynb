{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Preparing for Data\n",
    "# print('==> Preparing data..')\n",
    "\n",
    "# Training Data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "# Testing Data preparation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def tb_writer(optim):\n",
    "    #timestamp = time.strftime('%Y%m%d_%H_%M_%S')\n",
    "    timestamp = time.strftime(optim)\n",
    "    writer = SummaryWriter(log_dir=\"F:\\PythonProject\\ECE579_Intro_to_DL\\HW4\\log_dir/\"+timestamp)\n",
    "    return writer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 120, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        x = self.model(x)\n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class LeNetWithDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetWithDropout, self).__init__()\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 120, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        x = self.model(x)\n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class LeNetWithBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetWithBN, self).__init__()\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 120, kernel_size=5),\n",
    "            nn.BatchNorm2d(120),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        x = self.model(x)\n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, criterion, writer):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "    train_loss = total_loss/len(train_loader.dataset)\n",
    "    print(\"Epoch :{}\\tLoss :{:.6f}\".format(epoch, train_loss))\n",
    "    writer.add_scalar(\"Train Loss\", train_loss, epoch)\n",
    "    writer.flush()\n",
    "    # return train_loss\n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "        # if batch_idx % 10 == 0:\n",
    "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        #                100. * batch_idx / len(train_loader), loss.item()/len(train_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion, epoch, writer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "        correct /= total\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(\"Average Test Loss :{:.4f}, Accuracy :{:.2f}%\\n\".format(test_loss, correct * 100.0))\n",
    "        writer.add_scalar(\"Test Loss\", test_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy\", correct, epoch)\n",
    "        writer.flush()\n",
    "        # return test_loss, correct\n",
    "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    #     test_loss, correct, len(test_loader.dataset),\n",
    "    #     100. * correct / len(test_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch :1\tLoss :0.017831\n",
      "Average Test Loss :0.0222, Accuracy :20.25%\n",
      "\n",
      "Epoch :2\tLoss :0.016403\n",
      "Average Test Loss :0.0197, Accuracy :29.48%\n",
      "\n",
      "Epoch :3\tLoss :0.015222\n",
      "Average Test Loss :0.0185, Accuracy :33.29%\n",
      "\n",
      "Epoch :4\tLoss :0.014381\n",
      "Average Test Loss :0.0173, Accuracy :36.84%\n",
      "\n",
      "Epoch :5\tLoss :0.013771\n",
      "Average Test Loss :0.0165, Accuracy :39.60%\n",
      "\n",
      "Epoch :6\tLoss :0.013330\n",
      "Average Test Loss :0.0160, Accuracy :41.70%\n",
      "\n",
      "Epoch :7\tLoss :0.012875\n",
      "Average Test Loss :0.0156, Accuracy :42.88%\n",
      "\n",
      "Epoch :8\tLoss :0.012541\n",
      "Average Test Loss :0.0150, Accuracy :45.07%\n",
      "\n",
      "Epoch :9\tLoss :0.012231\n",
      "Average Test Loss :0.0149, Accuracy :46.13%\n",
      "\n",
      "Epoch :10\tLoss :0.012014\n",
      "Average Test Loss :0.0144, Accuracy :47.54%\n",
      "\n",
      "Epoch :11\tLoss :0.011816\n",
      "Average Test Loss :0.0142, Accuracy :48.24%\n",
      "\n",
      "Epoch :12\tLoss :0.011646\n",
      "Average Test Loss :0.0139, Accuracy :49.35%\n",
      "\n",
      "Epoch :13\tLoss :0.011427\n",
      "Average Test Loss :0.0138, Accuracy :50.41%\n",
      "\n",
      "Epoch :14\tLoss :0.011236\n",
      "Average Test Loss :0.0138, Accuracy :50.40%\n",
      "\n",
      "Epoch :15\tLoss :0.011075\n",
      "Average Test Loss :0.0134, Accuracy :51.28%\n",
      "\n",
      "Epoch :16\tLoss :0.010947\n",
      "Average Test Loss :0.0130, Accuracy :53.13%\n",
      "\n",
      "Epoch :17\tLoss :0.010810\n",
      "Average Test Loss :0.0130, Accuracy :53.57%\n",
      "\n",
      "Epoch :18\tLoss :0.010655\n",
      "Average Test Loss :0.0127, Accuracy :54.60%\n",
      "\n",
      "Epoch :19\tLoss :0.010506\n",
      "Average Test Loss :0.0127, Accuracy :54.12%\n",
      "\n",
      "Epoch :20\tLoss :0.010465\n",
      "Average Test Loss :0.0126, Accuracy :55.11%\n",
      "\n",
      "Epoch :21\tLoss :0.010324\n",
      "Average Test Loss :0.0124, Accuracy :55.43%\n",
      "\n",
      "Epoch :22\tLoss :0.010216\n",
      "Average Test Loss :0.0121, Accuracy :56.39%\n",
      "\n",
      "Epoch :23\tLoss :0.010128\n",
      "Average Test Loss :0.0121, Accuracy :56.80%\n",
      "\n",
      "Epoch :24\tLoss :0.010024\n",
      "Average Test Loss :0.0121, Accuracy :57.41%\n",
      "\n",
      "Epoch :25\tLoss :0.009937\n",
      "Average Test Loss :0.0117, Accuracy :58.32%\n",
      "\n",
      "Epoch :26\tLoss :0.009832\n",
      "Average Test Loss :0.0120, Accuracy :56.65%\n",
      "\n",
      "Epoch :27\tLoss :0.009772\n",
      "Average Test Loss :0.0120, Accuracy :56.99%\n",
      "\n",
      "Epoch :28\tLoss :0.009667\n",
      "Average Test Loss :0.0114, Accuracy :59.96%\n",
      "\n",
      "Epoch :29\tLoss :0.009553\n",
      "Average Test Loss :0.0118, Accuracy :57.89%\n",
      "\n",
      "Epoch :30\tLoss :0.009474\n",
      "Average Test Loss :0.0114, Accuracy :59.57%\n",
      "\n",
      "Epoch :31\tLoss :0.009466\n",
      "Average Test Loss :0.0113, Accuracy :59.99%\n",
      "\n",
      "Epoch :32\tLoss :0.009323\n",
      "Average Test Loss :0.0113, Accuracy :60.43%\n",
      "\n",
      "Epoch :33\tLoss :0.009333\n",
      "Average Test Loss :0.0112, Accuracy :60.04%\n",
      "\n",
      "Epoch :34\tLoss :0.009226\n",
      "Average Test Loss :0.0111, Accuracy :61.43%\n",
      "\n",
      "Epoch :35\tLoss :0.009180\n",
      "Average Test Loss :0.0109, Accuracy :61.76%\n",
      "\n",
      "Epoch :36\tLoss :0.009117\n",
      "Average Test Loss :0.0110, Accuracy :61.77%\n",
      "\n",
      "Epoch :37\tLoss :0.009060\n",
      "Average Test Loss :0.0107, Accuracy :62.36%\n",
      "\n",
      "Epoch :38\tLoss :0.008959\n",
      "Average Test Loss :0.0107, Accuracy :62.31%\n",
      "\n",
      "Epoch :39\tLoss :0.008934\n",
      "Average Test Loss :0.0107, Accuracy :62.76%\n",
      "\n",
      "Epoch :40\tLoss :0.008911\n",
      "Average Test Loss :0.0106, Accuracy :62.80%\n",
      "\n",
      "Epoch :41\tLoss :0.008802\n",
      "Average Test Loss :0.0106, Accuracy :62.47%\n",
      "\n",
      "Epoch :42\tLoss :0.008817\n",
      "Average Test Loss :0.0105, Accuracy :63.38%\n",
      "\n",
      "Epoch :43\tLoss :0.008698\n",
      "Average Test Loss :0.0105, Accuracy :63.23%\n",
      "\n",
      "Epoch :44\tLoss :0.008701\n",
      "Average Test Loss :0.0103, Accuracy :64.15%\n",
      "\n",
      "Epoch :45\tLoss :0.008640\n",
      "Average Test Loss :0.0103, Accuracy :64.35%\n",
      "\n",
      "Epoch :46\tLoss :0.008626\n",
      "Average Test Loss :0.0103, Accuracy :64.37%\n",
      "\n",
      "Epoch :47\tLoss :0.008525\n",
      "Average Test Loss :0.0103, Accuracy :64.31%\n",
      "\n",
      "Epoch :48\tLoss :0.008504\n",
      "Average Test Loss :0.0103, Accuracy :63.87%\n",
      "\n",
      "Epoch :49\tLoss :0.008473\n",
      "Average Test Loss :0.0105, Accuracy :62.79%\n",
      "\n",
      "Epoch :50\tLoss :0.008434\n",
      "Average Test Loss :0.0100, Accuracy :65.06%\n",
      "\n",
      "Epoch :1\tLoss :0.017861\n",
      "Average Test Loss :0.0222, Accuracy :20.46%\n",
      "\n",
      "Epoch :2\tLoss :0.016855\n",
      "Average Test Loss :0.0202, Accuracy :28.06%\n",
      "\n",
      "Epoch :3\tLoss :0.015910\n",
      "Average Test Loss :0.0192, Accuracy :30.94%\n",
      "\n",
      "Epoch :4\tLoss :0.015303\n",
      "Average Test Loss :0.0182, Accuracy :34.27%\n",
      "\n",
      "Epoch :5\tLoss :0.014662\n",
      "Average Test Loss :0.0174, Accuracy :36.73%\n",
      "\n",
      "Epoch :6\tLoss :0.014191\n",
      "Average Test Loss :0.0171, Accuracy :37.98%\n",
      "\n",
      "Epoch :7\tLoss :0.013876\n",
      "Average Test Loss :0.0163, Accuracy :40.68%\n",
      "\n",
      "Epoch :8\tLoss :0.013626\n",
      "Average Test Loss :0.0160, Accuracy :41.76%\n",
      "\n",
      "Epoch :9\tLoss :0.013417\n",
      "Average Test Loss :0.0157, Accuracy :43.32%\n",
      "\n",
      "Epoch :10\tLoss :0.013208\n",
      "Average Test Loss :0.0155, Accuracy :44.08%\n",
      "\n",
      "Epoch :11\tLoss :0.013058\n",
      "Average Test Loss :0.0152, Accuracy :45.33%\n",
      "\n",
      "Epoch :12\tLoss :0.012893\n",
      "Average Test Loss :0.0150, Accuracy :45.40%\n",
      "\n",
      "Epoch :13\tLoss :0.012763\n",
      "Average Test Loss :0.0147, Accuracy :46.75%\n",
      "\n",
      "Epoch :14\tLoss :0.012615\n",
      "Average Test Loss :0.0147, Accuracy :47.09%\n",
      "\n",
      "Epoch :15\tLoss :0.012468\n",
      "Average Test Loss :0.0144, Accuracy :47.84%\n",
      "\n",
      "Epoch :16\tLoss :0.012333\n",
      "Average Test Loss :0.0142, Accuracy :48.82%\n",
      "\n",
      "Epoch :17\tLoss :0.012237\n",
      "Average Test Loss :0.0139, Accuracy :49.80%\n",
      "\n",
      "Epoch :18\tLoss :0.012094\n",
      "Average Test Loss :0.0141, Accuracy :49.82%\n",
      "\n",
      "Epoch :19\tLoss :0.012020\n",
      "Average Test Loss :0.0136, Accuracy :51.49%\n",
      "\n",
      "Epoch :20\tLoss :0.011854\n",
      "Average Test Loss :0.0135, Accuracy :51.57%\n",
      "\n",
      "Epoch :21\tLoss :0.011811\n",
      "Average Test Loss :0.0134, Accuracy :52.10%\n",
      "\n",
      "Epoch :22\tLoss :0.011662\n",
      "Average Test Loss :0.0137, Accuracy :50.76%\n",
      "\n",
      "Epoch :23\tLoss :0.011571\n",
      "Average Test Loss :0.0132, Accuracy :53.00%\n",
      "\n",
      "Epoch :24\tLoss :0.011500\n",
      "Average Test Loss :0.0131, Accuracy :52.47%\n",
      "\n",
      "Epoch :25\tLoss :0.011397\n",
      "Average Test Loss :0.0129, Accuracy :53.53%\n",
      "\n",
      "Epoch :26\tLoss :0.011348\n",
      "Average Test Loss :0.0128, Accuracy :54.25%\n",
      "\n",
      "Epoch :27\tLoss :0.011238\n",
      "Average Test Loss :0.0128, Accuracy :54.40%\n",
      "\n",
      "Epoch :28\tLoss :0.011195\n",
      "Average Test Loss :0.0125, Accuracy :55.08%\n",
      "\n",
      "Epoch :29\tLoss :0.011089\n",
      "Average Test Loss :0.0126, Accuracy :55.33%\n",
      "\n",
      "Epoch :30\tLoss :0.011006\n",
      "Average Test Loss :0.0125, Accuracy :55.21%\n",
      "\n",
      "Epoch :31\tLoss :0.010964\n",
      "Average Test Loss :0.0125, Accuracy :54.90%\n",
      "\n",
      "Epoch :32\tLoss :0.010901\n",
      "Average Test Loss :0.0124, Accuracy :55.58%\n",
      "\n",
      "Epoch :33\tLoss :0.010833\n",
      "Average Test Loss :0.0122, Accuracy :56.68%\n",
      "\n",
      "Epoch :34\tLoss :0.010767\n",
      "Average Test Loss :0.0121, Accuracy :57.27%\n",
      "\n",
      "Epoch :35\tLoss :0.010713\n",
      "Average Test Loss :0.0119, Accuracy :58.04%\n",
      "\n",
      "Epoch :36\tLoss :0.010603\n",
      "Average Test Loss :0.0120, Accuracy :56.83%\n",
      "\n",
      "Epoch :37\tLoss :0.010577\n",
      "Average Test Loss :0.0121, Accuracy :56.67%\n",
      "\n",
      "Epoch :38\tLoss :0.010478\n",
      "Average Test Loss :0.0119, Accuracy :56.96%\n",
      "\n",
      "Epoch :39\tLoss :0.010418\n",
      "Average Test Loss :0.0118, Accuracy :57.63%\n",
      "\n",
      "Epoch :40\tLoss :0.010399\n",
      "Average Test Loss :0.0116, Accuracy :59.00%\n",
      "\n",
      "Epoch :41\tLoss :0.010277\n",
      "Average Test Loss :0.0116, Accuracy :58.59%\n",
      "\n",
      "Epoch :42\tLoss :0.010238\n",
      "Average Test Loss :0.0115, Accuracy :59.56%\n",
      "\n",
      "Epoch :43\tLoss :0.010243\n",
      "Average Test Loss :0.0113, Accuracy :60.06%\n",
      "\n",
      "Epoch :44\tLoss :0.010210\n",
      "Average Test Loss :0.0114, Accuracy :59.52%\n",
      "\n",
      "Epoch :45\tLoss :0.010122\n",
      "Average Test Loss :0.0114, Accuracy :59.73%\n",
      "\n",
      "Epoch :46\tLoss :0.010038\n",
      "Average Test Loss :0.0112, Accuracy :60.07%\n",
      "\n",
      "Epoch :47\tLoss :0.010029\n",
      "Average Test Loss :0.0112, Accuracy :60.29%\n",
      "\n",
      "Epoch :48\tLoss :0.009960\n",
      "Average Test Loss :0.0112, Accuracy :59.99%\n",
      "\n",
      "Epoch :49\tLoss :0.009924\n",
      "Average Test Loss :0.0111, Accuracy :60.69%\n",
      "\n",
      "Epoch :50\tLoss :0.009837\n",
      "Average Test Loss :0.0109, Accuracy :61.43%\n",
      "\n",
      "Epoch :1\tLoss :0.016860\n",
      "Average Test Loss :0.0191, Accuracy :33.11%\n",
      "\n",
      "Epoch :2\tLoss :0.014378\n",
      "Average Test Loss :0.0170, Accuracy :37.74%\n",
      "\n",
      "Epoch :3\tLoss :0.013124\n",
      "Average Test Loss :0.0156, Accuracy :42.37%\n",
      "\n",
      "Epoch :4\tLoss :0.012411\n",
      "Average Test Loss :0.0149, Accuracy :45.52%\n",
      "\n",
      "Epoch :5\tLoss :0.011928\n",
      "Average Test Loss :0.0142, Accuracy :48.38%\n",
      "\n",
      "Epoch :6\tLoss :0.011560\n",
      "Average Test Loss :0.0136, Accuracy :50.47%\n",
      "\n",
      "Epoch :7\tLoss :0.011249\n",
      "Average Test Loss :0.0137, Accuracy :50.35%\n",
      "\n",
      "Epoch :8\tLoss :0.010941\n",
      "Average Test Loss :0.0130, Accuracy :52.82%\n",
      "\n",
      "Epoch :9\tLoss :0.010690\n",
      "Average Test Loss :0.0128, Accuracy :54.36%\n",
      "\n",
      "Epoch :10\tLoss :0.010431\n",
      "Average Test Loss :0.0123, Accuracy :55.55%\n",
      "\n",
      "Epoch :11\tLoss :0.010233\n",
      "Average Test Loss :0.0122, Accuracy :56.19%\n",
      "\n",
      "Epoch :12\tLoss :0.010017\n",
      "Average Test Loss :0.0118, Accuracy :58.22%\n",
      "\n",
      "Epoch :13\tLoss :0.009819\n",
      "Average Test Loss :0.0116, Accuracy :58.35%\n",
      "\n",
      "Epoch :14\tLoss :0.009663\n",
      "Average Test Loss :0.0117, Accuracy :57.83%\n",
      "\n",
      "Epoch :15\tLoss :0.009507\n",
      "Average Test Loss :0.0112, Accuracy :60.38%\n",
      "\n",
      "Epoch :16\tLoss :0.009352\n",
      "Average Test Loss :0.0112, Accuracy :59.96%\n",
      "\n",
      "Epoch :17\tLoss :0.009219\n",
      "Average Test Loss :0.0110, Accuracy :60.83%\n",
      "\n",
      "Epoch :18\tLoss :0.009138\n",
      "Average Test Loss :0.0112, Accuracy :59.69%\n",
      "\n",
      "Epoch :19\tLoss :0.009010\n",
      "Average Test Loss :0.0109, Accuracy :60.99%\n",
      "\n",
      "Epoch :20\tLoss :0.008881\n",
      "Average Test Loss :0.0105, Accuracy :62.95%\n",
      "\n",
      "Epoch :21\tLoss :0.008832\n",
      "Average Test Loss :0.0105, Accuracy :62.32%\n",
      "\n",
      "Epoch :22\tLoss :0.008711\n",
      "Average Test Loss :0.0105, Accuracy :62.28%\n",
      "\n",
      "Epoch :23\tLoss :0.008628\n",
      "Average Test Loss :0.0103, Accuracy :63.08%\n",
      "\n",
      "Epoch :24\tLoss :0.008596\n",
      "Average Test Loss :0.0102, Accuracy :63.72%\n",
      "\n",
      "Epoch :25\tLoss :0.008510\n",
      "Average Test Loss :0.0104, Accuracy :62.64%\n",
      "\n",
      "Epoch :26\tLoss :0.008447\n",
      "Average Test Loss :0.0102, Accuracy :63.73%\n",
      "\n",
      "Epoch :27\tLoss :0.008361\n",
      "Average Test Loss :0.0102, Accuracy :63.51%\n",
      "\n",
      "Epoch :28\tLoss :0.008342\n",
      "Average Test Loss :0.0099, Accuracy :64.43%\n",
      "\n",
      "Epoch :29\tLoss :0.008250\n",
      "Average Test Loss :0.0099, Accuracy :64.88%\n",
      "\n",
      "Epoch :30\tLoss :0.008190\n",
      "Average Test Loss :0.0098, Accuracy :65.23%\n",
      "\n",
      "Epoch :31\tLoss :0.008159\n",
      "Average Test Loss :0.0100, Accuracy :64.43%\n",
      "\n",
      "Epoch :32\tLoss :0.008136\n",
      "Average Test Loss :0.0097, Accuracy :65.37%\n",
      "\n",
      "Epoch :33\tLoss :0.008055\n",
      "Average Test Loss :0.0099, Accuracy :64.73%\n",
      "\n",
      "Epoch :34\tLoss :0.008051\n",
      "Average Test Loss :0.0097, Accuracy :65.26%\n",
      "\n",
      "Epoch :35\tLoss :0.007949\n",
      "Average Test Loss :0.0094, Accuracy :66.63%\n",
      "\n",
      "Epoch :36\tLoss :0.007940\n",
      "Average Test Loss :0.0097, Accuracy :65.16%\n",
      "\n",
      "Epoch :37\tLoss :0.007895\n",
      "Average Test Loss :0.0097, Accuracy :65.66%\n",
      "\n",
      "Epoch :38\tLoss :0.007868\n",
      "Average Test Loss :0.0102, Accuracy :63.66%\n",
      "\n",
      "Epoch :39\tLoss :0.007811\n",
      "Average Test Loss :0.0093, Accuracy :67.17%\n",
      "\n",
      "Epoch :40\tLoss :0.007801\n",
      "Average Test Loss :0.0095, Accuracy :66.22%\n",
      "\n",
      "Epoch :41\tLoss :0.007748\n",
      "Average Test Loss :0.0096, Accuracy :66.15%\n",
      "\n",
      "Epoch :42\tLoss :0.007749\n",
      "Average Test Loss :0.0093, Accuracy :67.18%\n",
      "\n",
      "Epoch :43\tLoss :0.007673\n",
      "Average Test Loss :0.0092, Accuracy :67.51%\n",
      "\n",
      "Epoch :44\tLoss :0.007643\n",
      "Average Test Loss :0.0093, Accuracy :66.93%\n",
      "\n",
      "Epoch :45\tLoss :0.007584\n",
      "Average Test Loss :0.0096, Accuracy :66.12%\n",
      "\n",
      "Epoch :46\tLoss :0.007623\n",
      "Average Test Loss :0.0093, Accuracy :67.18%\n",
      "\n",
      "Epoch :47\tLoss :0.007544\n",
      "Average Test Loss :0.0091, Accuracy :68.68%\n",
      "\n",
      "Epoch :48\tLoss :0.007519\n",
      "Average Test Loss :0.0090, Accuracy :68.61%\n",
      "\n",
      "Epoch :49\tLoss :0.007508\n",
      "Average Test Loss :0.0090, Accuracy :68.15%\n",
      "\n",
      "Epoch :50\tLoss :0.007484\n",
      "Average Test Loss :0.0091, Accuracy :68.06%\n",
      "\n",
      "Traning and Testing total excution time is: 1318.7285418510437 seconds \n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "# Training settings\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "lr = 0.001\n",
    "save_model = False\n",
    "torch.manual_seed(100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "models = {\"LeNet\": LeNet(), \"LeNet With Dropout\":LeNetWithDropout(), \"LeNet With BN\": LeNetWithBN()}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for model_name in models:\n",
    "    log_writer = tb_writer(model_name)\n",
    "    model = models[model_name].to(device=device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch, criterion, log_writer)\n",
    "        test(model, device, test_loader, criterion, epoch, log_writer)\n",
    "        log_writer.close()\n",
    "# if (save_model):\n",
    "#     torch.save(model.state_dict(), \"cifar_lenet.pt\")\n",
    "time1 = time.time()\n",
    "print('Traning and Testing total excution time is: %s seconds ' % (time1 - time0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}